{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird Data Download\n",
    "\n",
    "Download bird data from [Macaulay Library – Collecting, Archiving, and Distributing Wildlife Media Since 1929](https://www.macaulaylibrary.org/#_ga=2.137140912.1870833980.1539159576-815199649.1538639191)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Data Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "from io import BytesIO\n",
    "import time\n",
    "import pandas as pd\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdMetaDataDownloader(object):\n",
    "    def __init__(self):\n",
    "        self.cookies = {\n",
    "            \"__hssrc\": \"1\",\n",
    "            \"__hstc\": \"264660688.9cc6bee4b68d06ca45c0fdddce762800.1539180999451.1539180999451.1539180999451.1\",\n",
    "            \"_dc_gtm_UA-51396009-1\": \"1\",\n",
    "            \"_ga\": \"GA1.3.42668022.1539180956\",\n",
    "            \"_gid\": \"GA1.3.2078748312.1539180956\",\n",
    "            \"hubspotutk\": \"9cc6bee4b68d06ca45c0fdddce762800\",\n",
    "            \"PIZOTE_SESSIONID\": \"19E257E0ACD97C2086B7E21786D242DC\",\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def download_an_query_in_a_month_in_a_year(self, query, taxon_code, year, month):\n",
    "        url = \"https://search.macaulaylibrary.org/catalog.csv\"\n",
    "        parameter = {\n",
    "            'mediaType': 'p',\n",
    "            'taxonCode': taxon_code,\n",
    "            'q': query,\n",
    "            'yr': 'YCUSTOM',\n",
    "            'mr': 'MCUSTOM',\n",
    "            'sort': 'rating_rank_desc',\n",
    "            'by': year,\n",
    "            'ey': year,\n",
    "            'bmo': month,\n",
    "            'emo': month,\n",
    "        }\n",
    "        \n",
    "        r = requests.get(url, params=parameter, cookies=self.cookies)\n",
    "\n",
    "        if len(r.content) > 703:\n",
    "            os.makedirs(os.path.join('..', f'data/meta/{taxon_code}'), exist_ok=True)\n",
    "            with open(os.path.join('..', f'data/meta/{taxon_code}/{taxon_code}_{year}_{month:0>2}.csv'), 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    def download_random_query_in_a_month_in_a_year(self, year, month):\n",
    "        url = \"https://search.macaulaylibrary.org/catalog.csv\"\n",
    "        parameter = {\n",
    "            'mediaType': 'p',\n",
    "            'yr': 'YCUSTOM',\n",
    "            'mr': 'MCUSTOM',\n",
    "            'sort': 'rating_rank_desc',\n",
    "            'by': year,\n",
    "            'ey': year,\n",
    "            'bmo': month,\n",
    "            'emo': month,\n",
    "        }\n",
    "        \n",
    "        r = requests.get(url, params=parameter, cookies=self.cookies)\n",
    "\n",
    "        if len(r.content) > 703:\n",
    "            os.makedirs(os.path.join('..', f'data/meta/random'), exist_ok=True)\n",
    "            with open(os.path.join('..', f'data/meta/random/{year}_{month:0>2}.csv'), 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    def download_an_query_all_time(self, query, taxon_code):\n",
    "        for year in tqdm(range(1900, 2019)):\n",
    "            for month in range(1, 13):\n",
    "                self.download_an_query_in_a_month_in_a_year(query, taxon_code, year, month)\n",
    "                \n",
    "        return 0\n",
    "    \n",
    "    def download_random_query_all_time(self):\n",
    "        for year in tqdm(range(1900, 2019)):\n",
    "            for month in range(1, 13):\n",
    "                self.download_random_query_in_a_month_in_a_year(year, month)\n",
    "                \n",
    "        return 0\n",
    "    \n",
    "    def download_all_egrets(self):\n",
    "        querys = [\n",
    "            'Great Egret - Ardea alba',\n",
    "            'Intermediate Egret - Ardea intermedia',\n",
    "            'Little Egret - Egretta garzetta',\n",
    "            'Cattle Egret - Bubulcus ibis',\n",
    "        ]\n",
    "        \n",
    "        taxon_codes = [\n",
    "            'greegr',\n",
    "            'integr',\n",
    "            'litegr',\n",
    "            'categr',\n",
    "        ]\n",
    "        \n",
    "        for query, taxon_code in zip(querys, taxon_codes):\n",
    "            print(f'{query}: ')\n",
    "            time.sleep(1)\n",
    "            self.download_an_query_all_time(query, taxon_code)\n",
    "            \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_dldr = BirdMetaDataDownloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cattle Egret - Bubulcus ibis: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 43/43 [13:45<00:00, 19.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmd_dldr.download_all_egrets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [44:23<00:00, 22.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmd_dldr.download_random_query_all_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Meta Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we select data since 2010, for aligning data and removing bad quatity data. We do this via create directories named \"old\" to store the meta data for old data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_meta_data(taxon_code, dir_path):\n",
    "    file_paths = os.listdir(dir_path)\n",
    "    file_paths = [os.path.join(dir_path, x) for x in file_paths if '.csv' in x]\n",
    "    \n",
    "    dfs = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path) \n",
    "        dfs.append(df)\n",
    "    \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    if taxon_code == \"random\":\n",
    "        df = df[df.loc[:, 'Common Name'].str.contains(\"Great Egret\") == False]\n",
    "        df = df[df.loc[:, 'Common Name'].str.contains(\"Intermediate Egret\") == False]\n",
    "        df = df[df.loc[:, 'Common Name'].str.contains(\"Little Egret\") == False]\n",
    "        df = df[df.loc[:, 'Common Name'].str.contains(\"Cattle Egret\") == False]\n",
    "        \n",
    "    print(f'{taxon_code}: {len(df)} photos')\n",
    "    \n",
    "    df.to_csv(os.path.join('..', 'data/meta_merge', f'{taxon_code}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greegr: 35002 photos\n",
      "integr: 2239 photos\n",
      "litegr: 8480 photos\n",
      "categr: 19167 photos\n",
      "random: 105250 photos\n"
     ]
    }
   ],
   "source": [
    "taxon_codes = [\n",
    "    'greegr',\n",
    "    'integr',\n",
    "    'litegr',\n",
    "    'categr',\n",
    "    'random',\n",
    "]\n",
    "\n",
    "dir_names = [\n",
    "    os.path.join('..', 'data/meta/greegr'),\n",
    "    os.path.join('..', 'data/meta/integr'),\n",
    "    os.path.join('..', 'data/meta/litegr'),\n",
    "    os.path.join('..', 'data/meta/categr'),\n",
    "    os.path.join('..', 'data/meta/random'),\n",
    "]\n",
    "\n",
    "for taxon_code, dir_name in zip(taxon_codes, dir_names):\n",
    "    merge_meta_data(taxon_code, dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataDownloader(object):\n",
    "    def download_by_ml_id(self, taxon_code, ml_id):\n",
    "        url = f\"https://download.ams.birds.cornell.edu/api/v1/asset/{ml_id}/large\"\n",
    "        \n",
    "        r = requests.get(url)\n",
    "        \n",
    "        os.makedirs(os.path.join('..', f'data/data/{taxon_code}'), exist_ok=True)\n",
    "        with open(os.path.join('..', f'data/data/{taxon_code}/{ml_id}.jpg'), 'wb') as f:\n",
    "            f.write(r.content)\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    def download_by_file_sub(self, param):\n",
    "        taxon_code, ml_ids = param\n",
    "        \n",
    "        for ml_id in ml_ids:\n",
    "            self.download_by_ml_id(taxon_code, ml_id)\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    def download_by_file(self, taxon_code, file_path):\n",
    "        df = pd.read_csv(file_path, usecols=['ML Catalog #'])\n",
    "        \n",
    "        ml_ids = df.loc[:, 'ML Catalog #'].values\n",
    "        \n",
    "        for ml_id in tqdm(ml_ids):\n",
    "            self.download_by_ml_id(taxon_code, ml_id)\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def download_by_file_mt(self, taxon_code, file_path, nt=20):\n",
    "        df = pd.read_csv(file_path, usecols=['ML Catalog #'])\n",
    "        \n",
    "        ml_ids = df.loc[:, 'ML Catalog #'].values\n",
    "        ml_ids = np.array_split(ml_ids, nt)\n",
    "        taxon_codes = [taxon_code for i in range(nt)]\n",
    "        \n",
    "        pool = ThreadPool(nt) \n",
    "        pool.map(self.download_by_file_sub, zip(taxon_codes, ml_ids))\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def download_by_directory(self, taxon_code, dir_path):\n",
    "        file_paths = os.listdir(dir_path)\n",
    "        file_paths = [os.join(dir_path, x) for x in file_paths if '.csv' in x]\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            self.download_by_file(taxon_code, file_path)\n",
    "            \n",
    "        return 0\n",
    "            \n",
    "    def download_all(self):\n",
    "        taxon_codes = [\n",
    "            'greegr',\n",
    "            'integr',\n",
    "            'litegr',\n",
    "            'categr',\n",
    "            'random',\n",
    "        ]\n",
    "        \n",
    "        dir_names = [\n",
    "            os.path.join('..', 'data/meta/greegr'),\n",
    "            os.path.join('..', 'data/meta/integr'),\n",
    "            os.path.join('..', 'data/meta/litegr'),\n",
    "            os.path.join('..', 'data/meta/categr'),\n",
    "            os.path.join('..', 'data/meta/random'),\n",
    "        ]\n",
    "        \n",
    "        for taxon_code, dir_name in zip(taxon_codes, dir_names):\n",
    "            self.download_by_directory(taxon_code, dir_path)\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    def download_all_from_merge_meta(self, mt=False):\n",
    "        taxon_codes = [\n",
    "            'greegr',\n",
    "            'integr',\n",
    "            'litegr',\n",
    "            'categr',\n",
    "            'random',\n",
    "        ]\n",
    "        \n",
    "        file_paths = [\n",
    "            os.path.join('..', 'data/meta_merge/greegr.csv'),\n",
    "            os.path.join('..', 'data/meta_merge/integr.csv'),\n",
    "            os.path.join('..', 'data/meta_merge/litegr.csv'),\n",
    "            os.path.join('..', 'data/meta_merge/categr.csv'),\n",
    "            os.path.join('..', 'data/meta_merge/random.csv'),\n",
    "        ]\n",
    "        \n",
    "        for taxon_code, file_path in zip(taxon_codes, file_paths):\n",
    "            if mt:\n",
    "                self.download_by_file_mt(taxon_code, file_path, nt=10)\n",
    "            else:\n",
    "                self.download_by_file(taxon_code, file_path)\n",
    "            \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_dlr = BirdDataDownloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_dlr.download_all_from_merge_meta(mt=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
